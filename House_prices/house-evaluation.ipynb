{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Regression model to predict the house price"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import mean_absolute_error, r2_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('fivethirtyeight')\nplt.rcParams['figure.figsize'] = 12, 8","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reading data"},{"metadata":{"trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\ntest_data = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train set is comparable in size to the test set. Target column ('SalePrice') is present only in the train set."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Defining target value and input features"},{"metadata":{},"cell_type":"markdown","source":"This competition requires to predict total price of the house based on the given numeric and categorical features. In appraisal industry it is generally considered the best approach to estimate the price of real estate per sq.m or sq.ft. Total price is then calculated by multiplying the price per sq.m or sq.ft by the floor area. The reason for that being that size of the house in itself is a parameter, which affects the price per sq.m (the larger the house - the smaller the price per sq.m).\n\nPrice per sq.m also depends on the number of floors in the house. As a rule, the larger area is being concentrated on the first floor - the higher the price. Multi-storey houses with large basements are priced lower per sq.m than one-storey houses of similar total floor area."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Total square footage of the house (basement + 1st floor + 2nd floor)\ntrain_data['TotalSF'] = train_data['TotalBsmtSF'] + train_data['1stFlrSF'] + train_data['2ndFlrSF']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transform the original data for area in sq.ft on each floor into respective share of the total floor area\nfor column in ('TotalBsmtSF', '1stFlrSF', '2ndFlrSF'):\n    train_data[column] = train_data[column] / train_data['TotalSF']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transform measument of unfinished area in the basement into its share of the total basement area\ntrain_data['BsmtUnfSF'] = train_data['BsmtUnfSF'] / train_data['TotalBsmtSF']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transform measument of low quality area on all floors into its share of the total floor area\ntrain_data['LowQualFinSF'] = train_data['LowQualFinSF'] / train_data['TotalSF']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Target value will be modified to price per sq.ft of total area\ny_train = train_data['SalePrice'] / train_data['TotalSF']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Input features with the exception of the sale price and object ID\nx_train = train_data.drop(['Id', 'SalePrice'], axis='columns')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dealing with missing values and categorical features"},{"metadata":{},"cell_type":"markdown","source":"The data requires preprocessing in tearms of dealing with missing values and categorical features. Shuffling the train samples in this case is not necessary because original data is not sorted in any way.\n\nAll input features that are available in the dataset are relevant to the purpose of pricing the house, though they vary in their significance. The best approach would be to use as much original features as possible and fit the data to some kind of decision tree algorithm, which automatically detects the most important features."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking how many values are missing\nmissing_vals = train_data.isna().sum()\nprint(missing_vals[missing_vals > 0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some of the input features have high share of missing values, which makes them less useful for the model. These features are relatively few, and judging by their names we can safely assume they are not crucial. Only the features with less than 100 missing values will be retained for the further analysis."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop columns with more than 100 missing values\ncolumns_to_drop = missing_vals[missing_vals > 100].index\nx_train = x_train.drop(columns_to_drop, axis='columns')\nprint(columns_to_drop)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Missing values in the remaining columns will be imputed using 'median' strategy for numeric columns and 'most_frequent' strategy for categorical columns. Some of the columns that do not contain NaNs in the train set have missing values in the test set. To simplify and automate data processing we add numeric and categorical features to lists, which will be used in a column transformer as part of the data processing and modelling pipeline."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Columns by data type\ncat_columns = list(x_train.select_dtypes(include=['category', 'object']).columns)\nnum_columns = list(x_train.select_dtypes(include=['number']).columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Imputing missing values, one-hot-encoding categorical columns.\n# Scaler is not being used because RandomForest algorithm does not require scaling numeric values.\nimp_median = SimpleImputer(strategy='median')\nimp_freq = SimpleImputer(strategy='most_frequent')\nohe = OneHotEncoder(sparse=False)\n\ncat_transformer = make_pipeline(imp_freq, ohe)\n\ncol_transformer = make_column_transformer((imp_median, num_columns),\n                                          (cat_transformer, cat_columns),\n                                          remainder='passthrough')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Making a pipeline for regression model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Combine column transformer with the regression model\nregr_model = RandomForestRegressor()\npipe_RF = make_pipeline(col_transformer, regr_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training the model\npipe_RF.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Evaluating the model on the train set"},{"metadata":{},"cell_type":"markdown","source":"In practice when appraisal specialists create evaluation models they tend to filter out outliers - objects with uptypically high or low prices, that could not be justified by the stardard regression model. Outliers in the real estate market usually belong to one of the following groups:\n- unique properties with rare features that are not captured in the stardard description;\n- properties sold on special conditions (seller looking for a quick deal, etc.);\n- errors in property description.\n\nTaking that into account, the optimal metrics to evaluate the house price model would be R2 (determination coefficient) and MAE (Mean Absolute Error). MSE (Mean Squared Error) in this case should not be considered as it amplifies the importance of outliers."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting price per sq.ft\ny_pred = pipe_RF.predict(x_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluating the errors based on actual and predicted price per sq.ft\nMAE = mean_absolute_error(y_pred, y_train)\nR2 = r2_score(y_pred, y_train)\nprint(f'RandomForest price prediction per sq.ft\\nMAE = {MAE}\\nR2 = {R2}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Average value of the predicted parameter and MAE to average value ratio\nav_price_sqft = np.mean(y_train)\nprint(f'Average price per sq.ft = {av_price_sqft}\\nMAE/av.price = {MAE/av_price_sqft}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculating total price of the house\ntrain_result = pd.DataFrame({'PredPriceSF': y_pred, 'TotalSF': train_data['TotalSF']})\ntrain_result['PredPrice'] = train_result['PredPriceSF'] * train_result['TotalSF']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_result.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluating the errors based on actual and predicted price for the house\nMAE = mean_absolute_error(train_result['PredPrice'], train_data['SalePrice'])\nR2 = r2_score(train_result['PredPrice'], train_data['SalePrice'])\nprint(f'RandomForest price prediction\\nMAE={MAE}\\nR2={R2}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Average price of the house in the train set and MAE to average value ratio\nav_house_price = train_data['SalePrice'].mean()\nprint(f'Average house price = {av_house_price}\\nMAE/av.price = {MAE/av_house_price}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Absolute errors\ntrain_result['SalePrice'] = train_data['SalePrice']\ntrain_result['AbsError'] = abs(train_result['PredPrice'] - train_result['SalePrice'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribution of errors and their magnitude\nplt.hist(train_result['AbsError'], bins=20, log=True)\nplt.axvline(av_house_price, color='red', label='Average Price', linewidth=2)\nplt.legend()\nplt.xlabel('Absolute error')\nplt.ylabel('Frequency, log scale')\nplt.title('Distribution of Prediction Errors')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The histogram shows that large-scale errors are rare for the model and most likely caused by some errors in the original data or non-typical objects present in the dataset. These objects represent minor share of the training set, however they can significantly distort and skew the regression model.\n\nTo improve the model quality and robustness to extreme outliers we can eliminate them from the training set altogether. In this case the model will predict prices for typical houses more accurately but errors in regards to extreme outliers will not be eliminated. For practical business purposes this approach would be more useful than overfitting the model on nontypical data samples."},{"metadata":{"trusted":true},"cell_type":"code","source":"outliers = train_result[train_result['AbsError'] > 200_000]\noutliers_indexes = outliers.index\noutliers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing outliers from input data and targets\nx_train.drop(outliers_indexes, inplace=True)\ny_train.drop(outliers_indexes, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Retraining the model on data cleaned from extreme outliers\npipe_RF.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting price per suare foot\ny_pred = pipe_RF.predict(x_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluating the errors based on actual and predicted price per sq.ft\nMAE = mean_absolute_error(y_pred, y_train)\nR2 = r2_score(y_pred, y_train)\nprint(f'RandomForest price prediction per sq.ft\\nMAE = {MAE}\\nR2 = {R2}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To improve prediction accuracy we can train other regression models on the same data cleaned from extreme outliers with the same preprocessing steps and compare the metrics with results demonstrated by the RandomForest model.\n\nWe will check the accuracy of GradientBoosting model. Unlike RandomForest, which can work with unscaled numeric data, for this model we will modify the column transformer to include scaling for numeric features."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Modifying the column transformer\nscaler = StandardScaler()\nnum_transformer = make_pipeline(imp_median, scaler)\ncol_transformer_scaled = make_column_transformer((num_transformer, num_columns),\n                                                 (cat_transformer, cat_columns),\n                                                 remainder='passthrough')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training GradientBoosting model\npipe_GB = make_pipeline(col_transformer_scaled, GradientBoostingRegressor())\npipe_GB.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluating the model\npipe_GB.predict(x_train)\nMAE = mean_absolute_error(y_pred, y_train)\nR2 = r2_score(y_pred, y_train)\nprint(f'GradientBoosting prediction per sq.ft.\\nMAE = {MAE}\\nR2 = {R2}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"GradientBoosting model did not improved the prediction accuracy. For this task both models are appropriate."},{"metadata":{},"cell_type":"markdown","source":"### Making prediction on the test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"# One of the test data samples contains NaN value in the 'TotalBsmtSF' column\ntest_data['TotalBsmtSF'].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can assume in this case that missing value means there is no basement in the house\ntest_data['TotalBsmtSF'] = test_data['TotalBsmtSF'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate total floor area of the houses in the test set\n# to be able to get the sale price from predicted price per sq.ft\ntest_data['TotalSF'] = test_data['TotalBsmtSF'] + test_data['1stFlrSF'] + test_data['2ndFlrSF']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transform the original data for area in sq.ft on each floor into respective share of the total floor area\nfor column in ('TotalBsmtSF', '1stFlrSF', '2ndFlrSF'):\n    test_data[column] = test_data[column] / test_data['TotalSF']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transform measument of unfinished area in the basement into its share of the total basement area\ntest_data['BsmtUnfSF'] = test_data['BsmtUnfSF'] / test_data['TotalBsmtSF']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transform measument of low quality area on all floors into its share of the total floor area\ntest_data['LowQualFinSF'] = test_data['LowQualFinSF'] / test_data['TotalSF']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop unnecessary columns from the test data\nx_test = test_data.drop('Id', axis='columns')\nx_test = x_test.drop(columns_to_drop, axis='columns')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicted price per sq.ft.\ny_pred = pipe_RF.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate total price based on the predicted price per sq.ft.\ntest_data['PredPriceSF'] = y_pred\ntest_data['SalePrice'] = test_data['TotalSF'] * test_data['PredPriceSF']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select data for submission\nsubmission = test_data[['Id', 'SalePrice']]\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Saving the results to csv file\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}