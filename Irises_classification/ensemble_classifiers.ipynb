{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры-константы для сопоставимости результатов моделей:\n",
    "SEED = 7\n",
    "NUM_TREES = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Данные для модели:\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Индексы для деления данных на 10 частей, т.к. исходные данные не перемешаны:\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем модели:\n",
    "model_ABC = AdaBoostClassifier(n_estimators=NUM_TREES, random_state=SEED)\n",
    "model_RFC = RandomForestClassifier(n_estimators=NUM_TREES, random_state=SEED)\n",
    "model_GBC = GradientBoostingClassifier(n_estimators=NUM_TREES, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model_ABC, model_RFC, model_GBC]  # Список моделей для итерирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_accuracy(model, cv=skf, scoring='accuracy'):\n",
    "    \"\"\"Функция принимает модель классификации, выводит\n",
    "    параметры модели и показатели точности при кросс-валидации.\"\"\"\n",
    "    print(f'\\nПараметры модели:\\n{model}')\n",
    "    results = cross_val_score(model, X, y, cv=cv, scoring=scoring)\n",
    "    print(f'\\nСредняя точность модели при кросс-валидации: {results.mean()}')\n",
    "    for ind, accuracy in enumerate(results):\n",
    "        print(f'\\tВыборка №{ind+1}:\\tТочность: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(model):\n",
    "    \"\"\"Функция принимает и обучает модель классификации, делает прогноз\n",
    "    и выводит показатели точности модели на тестовой выборке.\"\"\"\n",
    "    model.fit(X_train, y_train)\n",
    "    prediction = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, prediction)\n",
    "    print(f'Точность модели на тестовой выборке: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Параметры модели:\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
      "                   n_estimators=30, random_state=7)\n",
      "\n",
      "Средняя точность модели при кросс-валидации: 0.9333333333333333\n",
      "\tВыборка №1:\tТочность: 0.9333333333333333\n",
      "\tВыборка №2:\tТочность: 0.8666666666666667\n",
      "\tВыборка №3:\tТочность: 0.9333333333333333\n",
      "\tВыборка №4:\tТочность: 0.9333333333333333\n",
      "\tВыборка №5:\tТочность: 1.0\n",
      "\tВыборка №6:\tТочность: 1.0\n",
      "\tВыборка №7:\tТочность: 0.9333333333333333\n",
      "\tВыборка №8:\tТочность: 0.8\n",
      "\tВыборка №9:\tТочность: 0.9333333333333333\n",
      "\tВыборка №10:\tТочность: 1.0\n",
      "Точность модели на тестовой выборке: 0.8666666666666667\n",
      "\n",
      "Параметры модели:\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=30,\n",
      "                       n_jobs=None, oob_score=False, random_state=7, verbose=0,\n",
      "                       warm_start=False)\n",
      "\n",
      "Средняя точность модели при кросс-валидации: 0.9533333333333334\n",
      "\tВыборка №1:\tТочность: 0.9333333333333333\n",
      "\tВыборка №2:\tТочность: 0.9333333333333333\n",
      "\tВыборка №3:\tТочность: 0.9333333333333333\n",
      "\tВыборка №4:\tТочность: 0.9333333333333333\n",
      "\tВыборка №5:\tТочность: 1.0\n",
      "\tВыборка №6:\tТочность: 1.0\n",
      "\tВыборка №7:\tТочность: 0.9333333333333333\n",
      "\tВыборка №8:\tТочность: 0.8666666666666667\n",
      "\tВыборка №9:\tТочность: 1.0\n",
      "\tВыборка №10:\tТочность: 1.0\n",
      "Точность модели на тестовой выборке: 0.8666666666666667\n",
      "\n",
      "Параметры модели:\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=30,\n",
      "                           n_iter_no_change=None, presort='auto',\n",
      "                           random_state=7, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "\n",
      "Средняя точность модели при кросс-валидации: 0.9466666666666667\n",
      "\tВыборка №1:\tТочность: 0.9333333333333333\n",
      "\tВыборка №2:\tТочность: 0.8666666666666667\n",
      "\tВыборка №3:\tТочность: 1.0\n",
      "\tВыборка №4:\tТочность: 0.9333333333333333\n",
      "\tВыборка №5:\tТочность: 1.0\n",
      "\tВыборка №6:\tТочность: 1.0\n",
      "\tВыборка №7:\tТочность: 0.9333333333333333\n",
      "\tВыборка №8:\tТочность: 0.8666666666666667\n",
      "\tВыборка №9:\tТочность: 0.9333333333333333\n",
      "\tВыборка №10:\tТочность: 1.0\n",
      "Точность модели на тестовой выборке: 0.9\n"
     ]
    }
   ],
   "source": [
    "# Последовательно оцениваем точность моделей:\n",
    "for model in models:\n",
    "    cross_val_accuracy(model)  # при кросс-валидации\n",
    "    test_accuracy(model)  # на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model(model, params, cv=skf, scoring='accuracy'):\n",
    "    \"\"\"Функция находит оптимальные параметры модели\n",
    "    через настройку гиперпараметров RandomizedSearchCV.\n",
    "    Принимает модель и словарь параметров.\n",
    "    Выводит параметры лучшей модели и возвращает ее.\"\"\"\n",
    "    print(f'\\nНастройка модели:\\n{model}')\n",
    "    model_tuned = RandomizedSearchCV(model, param_distributions=params,\n",
    "                                     n_iter=10, cv=skf,\n",
    "                                     scoring='accuracy',\n",
    "                                     random_state=SEED,\n",
    "                                     refit=True,\n",
    "                                     n_jobs=-1)\n",
    "    model_tuned.fit(X, y)\n",
    "    print('Параметры оптимальной модели:', model_tuned.best_params_)\n",
    "    print('Точность оптимальной модели:', model_tuned.best_score_)\n",
    "    return model_tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Словари параметров для моделей:\n",
    "params_ABC = {'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "              'learning_rate': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "              'algorithm': ['SAMME', 'SAMME.R']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_RFC = {'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "              'criterion': ['gini', 'entropy'],\n",
    "              'max_depth': [3, 5, 10, None],\n",
    "              'min_samples_split': [2, 3, 4],\n",
    "              'min_samples_leaf': [1, 2, 3],\n",
    "              'max_features': ['auto', None],\n",
    "              'bootstrap': [True, False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_GBC = {'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "              'learning_rate': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "              'subsample': [0.8, 0.9, 1.0],\n",
    "              'min_samples_split': [2, 3, 4],\n",
    "              'min_samples_leaf': [1, 2, 3],\n",
    "              'max_depth': [3, 5, 10, None],\n",
    "              'max_features': ['auto', None]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [params_ABC, params_RFC, params_GBC]  # Список для итерирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Настройка модели:\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
      "                   n_estimators=30, random_state=7)\n",
      "Параметры оптимальной модели: {'n_estimators': 30, 'learning_rate': 0.3, 'algorithm': 'SAMME'}\n",
      "Точность оптимальной модели: 0.9533333333333334\n",
      "\n",
      "Настройка модели:\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=30,\n",
      "                       n_jobs=None, oob_score=False, random_state=7, verbose=0,\n",
      "                       warm_start=False)\n",
      "Параметры оптимальной модели: {'n_estimators': 80, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': None, 'max_depth': 10, 'criterion': 'gini', 'bootstrap': True}\n",
      "Точность оптимальной модели: 0.9666666666666667\n",
      "\n",
      "Настройка модели:\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=30,\n",
      "                           n_iter_no_change=None, presort='auto',\n",
      "                           random_state=7, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "Параметры оптимальной модели: {'subsample': 0.9, 'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'auto', 'max_depth': None, 'learning_rate': 0.8}\n",
      "Точность оптимальной модели: 0.9533333333333334\n"
     ]
    }
   ],
   "source": [
    "models_tuned = []  # Список для добавления оптимальных моделей\n",
    "for model, pars in zip(models, params):\n",
    "    models_tuned.append(optimize_model(model, pars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
